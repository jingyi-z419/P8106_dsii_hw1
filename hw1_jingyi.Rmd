---
title: "Homework 1"
author: Jingyi Zhang
date: "2/6/21"
output: pdf_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(caret)
library(pls)
library(ggplot2)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%",
  message = FALSE,
  echo = TRUE,
  warning = FALSE,
  cache = TRUE
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
          
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Load dataset

```{r}
sol_test <-
  read_csv("./data/solubility_test.csv") %>% 
  janitor::clean_names()

sol_train <-
  read_csv("./data/solubility_train.csv") %>% 
  janitor::clean_names()

# training data
x_train <- model.matrix(solubility ~ ., sol_train)[ ,-1]
y_train <- sol_train$solubility

# test data
x_test <- model.matrix(solubility ~ ., sol_test)[ ,-1]
y_test <- sol_test$solubility
```

# (a) Fit a linear model using least squares on the training data and calculate the mean squared error using the test data.

```{r}
set.seed(7) 
ctrl1 <- trainControl(method = "cv", number = 10)
lm.fit <- train(solubility~.,
                data = sol_train,
                method = "lm",
                trControl = ctrl1)
RMSE(predict(lm.fit, newdata = sol_test), sol_test$solubility) 
```

# (b) Fit a ridge regression model on the training data, with lambda chosen by cross-validation. Report the test error.

```{r ridge}
set.seed(7)
ridge.fit <-
  train(solubility~.,
        data = sol_train,
        method = "glmnet",
        tuneGrid =
          expand.grid(alpha = 0,
                      lambda = exp(seq(5, -10, length = 1000))),
        trControl = ctrl1,
        preProcess = c("center", "scale"))

plot(ridge.fit, xTrans = log, pch = 1, col = "light blue")

ridge.fit$bestTune

RMSE(predict(ridge.fit, s = "lambda.min", newx = sol_test), sol_test$solubility)
```

# (c) Fit a lasso model on the training data, with lambda chosen by cross-validation. Report the test error and the number of non-zero coefficient estimates in your model.

```{r lasso}
set.seed(7)
lasso.fit <-
  train(solubility~.,
        data = sol_train,
        method = "glmnet",
        tuneGrid =
          expand.grid(alpha = 1,
                      lambda = exp(seq(0, -12, length = 1000))),
        trControl = ctrl1,
        preProcess = c("center", "scale"))
    
plot(lasso.fit, xTrans = log, col = "light blue", pch = 1)

lasso.fit$bestTune

RMSE(predict(lasso.fit, s = "lambda.min", newx = sol_test), sol_test$solubility)

sum(coef(lasso.fit$finalModel, lasso.fit$bestTune$lambda) != 0)
```

# (d) Fit a principle component regression model on the training data, with M chosen by cross-validation. Report the test error and the value of M selected by cross-validation.

```{r pcr}
ctrl2 <- trainControl(method = "cv", selectionFunction = "best")

set.seed(7)
pcr.fit <- 
  train(solubility~.,
        data = sol_train,
        method = "pcr",
        tuneGrid =
          data.frame(ncomp = seq(1, ncol(x_train))),
        trControl = ctrl2,
        preProcess = c("center", "scale"))

pcr.fit$bestTune

ggplot(pcr.fit, highlight = TRUE) + theme_bw()

RMSE(predict(pcr.fit, x_test), y_test)

mean((predict(pcr.fit, x_test) - y_test)^2)
```

# (e) Which model will you choose for predicting solubility?

```{r}
resamp <- resamples(list(
                        linear = lm.fit,
                        ridge = ridge.fit,
                        lasso = lasso.fit,
                        pcr = pcr.fit))
summary(resamp)

bwplot(resamp, metric = "RMSE")
```

Based on the numeric and graph outputs, lasso model has the smallest mean RMSE among all four models. Lasso will be chosen for predicting solubility.





